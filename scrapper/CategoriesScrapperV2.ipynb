{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrap websites mentioned in file to collect food categories. It saves scrapped data after each page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Comment\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes there is an error if you don't to specified number of rows 'nrows' to read from a file. If it happens check first how many rows are there in the scv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToRead = 'C:/Users/Patrycja/Desktop/Uni Koblenz/CSS/GermansFoodPreferences/scrapper/files/jan/data_2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(pathToRead, sep=',', encoding='ISO-8859-1')#, nrows=nrows)#, engine='python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>country_region</th>\n",
       "      <th>zip</th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>target_link</th>\n",
       "      <th>origin_link</th>\n",
       "      <th>host_type</th>\n",
       "      <th>recipe_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2013-07-28 13:59:59</td>\n",
       "      <td>/rezept/404417/Knuspriger-Spanferkelrollbraten...</td>\n",
       "      <td>http://www.kochbar.de/rezepte/spanferkelrollbr...</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 5.1; rv:22.0) Gecko/20...</td>\n",
       "      <td>404417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2013-07-28 13:59:59</td>\n",
       "      <td>/rezept/404417/Knuspriger-Spanferkelrollbraten...</td>\n",
       "      <td>http://www.kochbar.de/rezepte/spanferkelrollbr...</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 5.1; rv:22.0) Gecko/20...</td>\n",
       "      <td>404417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE</td>\n",
       "      <td>4</td>\n",
       "      <td>22117</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>2013-07-02 04:06:39</td>\n",
       "      <td>/rezept/106165/Spargelsalat-mit-Rinderfilet-un...</td>\n",
       "      <td>http://www.google.de/url?sa=t&amp;rct=j&amp;q=salat%20...</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; WOW64; rv:21.0) G...</td>\n",
       "      <td>106165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>Frankfurt_Am_Main</td>\n",
       "      <td>2013-07-14 10:00:38</td>\n",
       "      <td>/rezept/470972/Nudelsalat-mit-Gemuese.html</td>\n",
       "      <td>-</td>\n",
       "      <td>Mozilla/5.0 (compatible; YandexBot/3.0; +http:...</td>\n",
       "      <td>470972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE</td>\n",
       "      <td>16</td>\n",
       "      <td>14169</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2013-07-22 16:00:17</td>\n",
       "      <td>/rezept/417178/Ravioli-gefuellt-mit-Pilzen.html</td>\n",
       "      <td>-</td>\n",
       "      <td>Mozilla/5.0 (iPad; CPU OS 6_1_3 like Mac OS X)...</td>\n",
       "      <td>417178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  country_region    zip               city                 date  \\\n",
       "0      DE              16     -1             Berlin  2013-07-28 13:59:59   \n",
       "1      DE              16     -1             Berlin  2013-07-28 13:59:59   \n",
       "2      DE               4  22117            Hamburg  2013-07-02 04:06:39   \n",
       "3      DE               5     -1  Frankfurt_Am_Main  2013-07-14 10:00:38   \n",
       "4      DE              16  14169             Berlin  2013-07-22 16:00:17   \n",
       "\n",
       "                                         target_link  \\\n",
       "0  /rezept/404417/Knuspriger-Spanferkelrollbraten...   \n",
       "1  /rezept/404417/Knuspriger-Spanferkelrollbraten...   \n",
       "2  /rezept/106165/Spargelsalat-mit-Rinderfilet-un...   \n",
       "3         /rezept/470972/Nudelsalat-mit-Gemuese.html   \n",
       "4    /rezept/417178/Ravioli-gefuellt-mit-Pilzen.html   \n",
       "\n",
       "                                         origin_link  \\\n",
       "0  http://www.kochbar.de/rezepte/spanferkelrollbr...   \n",
       "1  http://www.kochbar.de/rezepte/spanferkelrollbr...   \n",
       "2  http://www.google.de/url?sa=t&rct=j&q=salat%20...   \n",
       "3                                                  -   \n",
       "4                                                  -   \n",
       "\n",
       "                                           host_type  recipe_id  \n",
       "0  Mozilla/5.0 (Windows NT 5.1; rv:22.0) Gecko/20...     404417  \n",
       "1  Mozilla/5.0 (Windows NT 5.1; rv:22.0) Gecko/20...     404417  \n",
       "2  Mozilla/5.0 (Windows NT 6.1; WOW64; rv:21.0) G...     106165  \n",
       "3  Mozilla/5.0 (compatible; YandexBot/3.0; +http:...     470972  \n",
       "4  Mozilla/5.0 (iPad; CPU OS 6_1_3 like Mac OS X)...     417178  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_comment(soup, wanted_comment='REZEPT-KATEGORIEN'):\n",
    "    found = False\n",
    "\n",
    "    comments = soup.find_all(string=lambda text:isinstance(text, Comment))\n",
    "    i = 0\n",
    "    while not found and i < len(comments):\n",
    "        node = comments[i]\n",
    "        if node.strip() == wanted_comment:\n",
    "            #print('comment found')\n",
    "            found = True\n",
    "\n",
    "        i+=1\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_categories(soup, wanted_class = 'rtli-pb-small'):\n",
    "    data = []\n",
    "    node = find_comment(soup)\n",
    "    startOfItems, endOfItems = False, False\n",
    "    \n",
    "    while not endOfItems and node.find_next_sibling():\n",
    "        node = node.find_next_sibling()\n",
    "\n",
    "        if node['class'][0] == wanted_class:\n",
    "            startOfItems = True\n",
    "\n",
    "            if node.findChild().name == 'a':\n",
    "                data.append(node.a.text)\n",
    "            elif node.findChild().name == 'span':\n",
    "                data.append(node.span.text)\n",
    "\n",
    "        elif startOfItems:\n",
    "            endOfItems = True\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'http://www.kochbar.de'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to specify with rows to process. If 'all_rows' is set to True, 'start_index' and 'end_index' is not taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index, end_index = 110, 120\n",
    "all_rows = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(listToConvert):\n",
    "    result = '['\n",
    "    for el in listToConvert:\n",
    "        result += el + ','\n",
    "    \n",
    "    result = result[:-1]\n",
    "    return result +']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improveText(text):\n",
    "    text = text.replace('ê','e')\n",
    "    text = text.replace('Ê','E')\n",
    "    \n",
    "    text = text.replace('ö','oe')\n",
    "    text = text.replace('Ö','Oe')\n",
    "    text = text.replace('ä','ae')\n",
    "    text = text.replace('Ä','Ae')\n",
    "    text = text.replace('ü','ue')\n",
    "    text = text.replace('Ü','Ue')\n",
    "    text = text.replace('ß','ss')\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        nr = ord(text[i])\n",
    "        if (nr >= 97 and nr <= 122) or (nr >=65 and nr <=90) or nr in [32, 34, 38, 39, 40, 41, 44, 45, 46, 47, 63, 91, 92, 93, 95]:\n",
    "            pass\n",
    "        else:\n",
    "            print('to replace:', text[i])\n",
    "            text = text.replace(text[i], '?')\n",
    "                \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToSave = 'scrapped_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "error_num = 0\n",
    "df_new = pd.DataFrame(columns=['date', 'recipe_id', 'country', 'region', 'city', 'categories'])\n",
    "f= open(pathToSave,'w')\n",
    "df_new.to_csv(f, index=None, header=True, encoding='utf-8', sep=',')\n",
    "f.close()\n",
    "\n",
    "df = pd.read_csv(pathToRead, sep=',', encoding='ISO-8859-1') #, nrows=nrows)#, engine='python'\n",
    "\n",
    "f= open(pathToSave, 'a')\n",
    "\n",
    "if not all_rows:\n",
    "    df = df[start_index:end_index]\n",
    "else:\n",
    "    start_index = 0\n",
    "\n",
    "with tqdm(total=nrows) as pbar:\n",
    "    for i in range(len(df)): \n",
    "        #print(domain + url)\n",
    "        url = df['target_link'][start_index + i]\n",
    "        response = requests.get(domain + url)\n",
    "\n",
    "        if response.url != 'https://www.kochbar.de/rezepte/' and response.status_code == 200:\n",
    "            #print('Request status ok!')\n",
    "            soup = BeautifulSoup(response.content.decode('utf-8','ignore'), \"lxml\")\n",
    "            categories = find_categories(soup)\n",
    "            #print('categories:', categories, '\\n')\n",
    "            #data.append(categories)\n",
    "\n",
    "            s = pd.DataFrame({'d': str(df['date'][start_index + i]), 'id': df['recipe_id'][start_index + i], 'country':df['country'][start_index + i], 'region':df['country_region'][start_index + i], 'city': improveText(df['city'][start_index + i]),'categories': improveText(str(categories))}, index=[0])\n",
    "        elif response.status_code == 200:\n",
    "            #print('This webpage is probably no longer available!')\n",
    "            #data.append(None)\n",
    "            s = pd.DataFrame({'d': df['date'][start_index + i], 'id': df['recipe_id'][start_index + i], 'country':df['country'][start_index + i], 'region':df['country_region'][start_index + i], 'city': improveText(df['city'][start_index + i]), 'categories': str([])}, index=[0])\n",
    "\n",
    "        else:\n",
    "            #print('Not correct request status: ', response.status_code)\n",
    "            s = pd.DataFrame({'d': df['date'][start_index + i], 'id': df['recipe_id'][start_index + i], 'country':df['country'][start_index + i], 'region':df['country_region'][start_index + i], 'city': improveText(df['city'][start_index + i]), 'categories': str([])}, index=[0])\n",
    "        try:\n",
    "            s.to_csv(f, index=None, header=False, encoding='utf-8', sep=',')\n",
    "        except UnicodeEncodeError:\n",
    "            print('UnicodeEncodeError')\n",
    "            print(s)\n",
    "            error_num += 1\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "f.close() \n",
    "print(time.time() - start)\n",
    "print('errors:', error_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1=pd.read_csv(pathToSave)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Europa',\n",
       " ' Fisch',\n",
       " ' Mittagstisch',\n",
       " ' Abendessen',\n",
       " ' Date',\n",
       " ' Fruehling',\n",
       " ' Sommer',\n",
       " ' Herbst',\n",
       " ' Winter',\n",
       " ' Hauptspeise',\n",
       " ' Gesund und Diaet',\n",
       " ' preiswerte',\n",
       " ' schnell & einfach',\n",
       " ' Italien',\n",
       " ' fettarm',\n",
       " ' glutenfrei',\n",
       " ' ohne Weizen']"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['categories'][1][2:-2].replace(\"'\",\"\").replace('\"','').split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
